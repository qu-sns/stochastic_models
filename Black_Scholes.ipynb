{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6af13b",
   "metadata": {},
   "source": [
    "# Black-Scholes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf26789",
   "metadata": {},
   "source": [
    "## Sommaire :\n",
    "\n",
    "* [**1.Modèle**](#0)\n",
    "\n",
    "* [**2.Calibration**](#1)\n",
    "\n",
    "* [**3.Validation**](#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5248d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules \n",
    "import requests  # Connexion à l'API de AlphaVantage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d1d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clé personnelle de l'API AlphaVantage\n",
    "key_API = 'LYMJQ6KR5QPKJ8W3'\n",
    "equity = 'IBM'   # choisir n'importe quelle equity\n",
    "\n",
    "# URL pour obtenir les données hebdomadaires ajustées\n",
    "url = f'https://www.alphavantage.co/query?function=TIME_SERIES_WEEKLY_ADJUSTED&symbol={equity}&apikey={key_API}'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "# Accès au sous-dictionnaire contenant les données\n",
    "time_serie = data['Weekly Adjusted Time Series']\n",
    "\n",
    "# Extraction des données de clôture \n",
    "df = pd.DataFrame({\n",
    "    \"Date\": pd.to_datetime(list(time_serie.keys())),\n",
    "    \"Stock Value\": [float(entry[\"4. close\"]) for entry in time_serie.values()]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934055a",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "## 1. Modèle :\n",
    "\n",
    "\n",
    "Soit $(\\Omega, \\mathcal{F}, \\mathbb{P})$ un espace probabilisé, soit $(\\mathcal{W}_t)_{t>0}$ un mouvement brownien sous $\\mathbb{P}$ et $(\\mathcal{S}_t)_{t>0}$ représentant la trajectoire d'un actif.\n",
    "\n",
    "Sous $\\mathbb{P}$, la dynamique de $\\mathcal{S}$ s'écrit :\n",
    "\n",
    "$$\n",
    "\\frac{dS_t}{S_t} = \\mu \\, dt + \\sigma \\, dW_t\n",
    "$$\n",
    "\n",
    "**Solution de l'EDS :** (Pas de schéma nécessaire)\n",
    "\n",
    "$$\n",
    "d(\\ln(S_t)) = \\frac{1}{S_t} dS_t - \\frac{1}{2} \\frac{1}{S_t^2} (dS_t)^2\n",
    "\\implies d(\\ln(S_t)) = \\frac{1}{S_t} \\big(S_t (\\mu  \\, dt + \\sigma \\, dW_t)\\big) - \\frac{1}{2} \\sigma^2 dt\n",
    "\\implies d(\\ln(S_t)) = \\left(\\mu  - \\frac{1}{2} \\sigma^2\\right) dt + \\sigma dW_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\ln(S_t) = \\ln(S_0) + \\left(\\mu  - \\frac{1}{2} \\sigma^2\\right)t + \\sigma W_t\n",
    "\\implies S_t = S_0 \\exp\\left(\\left(\\mu  - \\frac{1}{2} \\sigma^2\\right)t + \\sigma W_t\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\implies S_{t_k} = S_{t_{k-1}} \\exp\\left(\\left(\\mu  - \\frac{1}{2} \\sigma^2\\right)(t_k - t_{k-1}) + \\sigma \\left(W_{t_k} - W_{t_{k-1}}\\right)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\implies\n",
    "\\boxed{ \\ln \\Big(\\tfrac{S_{t_k}}{S_{t_{k-1}}}\\Big) \\,\\big|\\, \\mathcal{F}_s \n",
    "\\sim \\mathcal{N}\\!\\Big( \\big(\\mu-\\tfrac12\\sigma^2\\big)(t_k - t_{k-1}),\\; \\sigma^2(t_k - t_{k-1}) \\Big) }\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8127649",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## 2. Calibration :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BlackScholes:\n",
    "    \"\"\"\n",
    "    Modèle Black–Scholes (GBM) pour un actif S_t.\n",
    "\n",
    "    Attributs\n",
    "    ---------\n",
    "    S0 : float | None\n",
    "        Dernier prix observé de l’actif.\n",
    "    mu : float | None\n",
    "        Drift sous la mesure historique P (continu, annualisé).\n",
    "    sigma : float | None\n",
    "        Volatilité de l’actif (continue, annualisée).\n",
    "    q : float\n",
    "        Taux de dividende continu (annualisé).\n",
    "    dt : float\n",
    "        Pas de temps en années des données historiques (ex: 1/252).\n",
    "    meta : dict\n",
    "        Dictionnaire pour stocker des informations de calibration.\n",
    "    \"\"\"\n",
    "    S0: float | None = None\n",
    "    mu: float | None = None\n",
    "    sigma: float | None = None\n",
    "    q: float = 0.0\n",
    "    dt: float = 1/252\n",
    "    meta: dict = field(default_factory=dict)\n",
    "\n",
    "    # ---------- UTILITAIRES ----------\n",
    "    @staticmethod\n",
    "    def _to_log_returns(prices: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calcule les log-returns consécutifs : ln(S_t) - ln(S_{t-1}).\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        prices : np.ndarray\n",
    "            Tableau 1D des prix de l’actif (strictement positifs).\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Tableau 1D des log-returns, de longueur len(prices)-1.\n",
    "        \"\"\"\n",
    "        p = np.asarray(prices, float)\n",
    "        return np.diff(np.log(p))\n",
    "\n",
    "    @staticmethod\n",
    "    def infer_dt_from_dates(dates) -> float:\n",
    "        \"\"\"\n",
    "        Infère le pas moyen dt (en années) à partir d'une série de dates.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        dates : array-like\n",
    "            Liste ou série de dates (convertissable en pandas.DatetimeIndex).\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        float\n",
    "            Pas moyen dt exprimé en années (≈ années_totales / (n_points - 1)).\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        s = pd.to_datetime(dates).dropna().sort_values()\n",
    "        total_years = (s.iloc[-1] - s.iloc[0]) / pd.Timedelta(days=365.25)\n",
    "        return float(total_years) / (len(s) - 1)\n",
    "\n",
    "    # ---------- CALIBRATION ----------\n",
    "    def fit_from_prices(self, prices: np.ndarray, keep_S0: bool = True) -> tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Calibre mu et sigma du modèle par MLE à partir d'une série de prix.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        prices : np.ndarray\n",
    "            Tableau 1D des prix de l’actif (strictement positifs).\n",
    "        keep_S0 : bool, défaut True\n",
    "            - True : conserve self.S0 si déjà défini.\n",
    "            - False : met self.S0 au dernier prix observé.\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        tuple[float, float]\n",
    "            (mu, sigma) estimés, annualisés.\n",
    "        \"\"\"\n",
    "        lr = self._to_log_returns(prices)\n",
    "        if self.S0 is None or not keep_S0:\n",
    "            self.S0 = float(prices[0])\n",
    "\n",
    "        m = float(np.mean(lr))         # E[Δln S] = (mu - 0.5 sigma^2) dt\n",
    "        v = float(np.var(lr))          # Var[Δln S] = sigma^2 dt\n",
    "\n",
    "        sigma_hat = np.sqrt(v / self.dt)\n",
    "        mu_hat = (m / self.dt) + 0.5 * sigma_hat**2\n",
    "\n",
    "        self.mu, self.sigma = float(mu_hat), float(sigma_hat)\n",
    "        self.meta.update({\"method\": \"historical_mle\", \"n_obs\": len(lr), \"dt\": self.dt})\n",
    "        return self.mu, self.sigma\n",
    "\n",
    "    # ---------- SIMULATION ----------\n",
    "    def simulate_paths(\n",
    "        self,\n",
    "        T: float,\n",
    "        n_steps: int = 252,\n",
    "        S0: float | None = None,\n",
    "        n_paths: int = 1000,\n",
    "        seed: int | None = None,\n",
    "        rate_curve: np.ndarray | None = None,\n",
    "        emm: bool = False,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Simule des trajectoires de S_t selon un GBM.\n",
    "\n",
    "        Paramètres\n",
    "        ----------\n",
    "        T : float\n",
    "            Horizon de simulation (en années).\n",
    "        n_steps : int, défaut 252\n",
    "            Nombre de pas de temps sur [0, T].\n",
    "        S0 : float | None, défaut None\n",
    "            Prix initial de l’actif. Si None, utilise self.S0.\n",
    "        n_paths : int, défaut 1000\n",
    "            Nombre de trajectoires simulées.\n",
    "        seed : int | None, défaut None\n",
    "            Graine pour le générateur aléatoire (reproductibilité).\n",
    "        rate_curve : np.ndarray | None\n",
    "            Courbe zéro-coupon R(0,k) (taux continus) donnée pour k=1..K (années entières).\n",
    "            Utilisée si emm=True.\n",
    "        emm : bool, défaut False\n",
    "            - False : simulation sous P (mesure historique), drift = mu - q.\n",
    "            - True : simulation sous Q (mesure risque-neutre), drift = r_t - q.\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Matrice (n_paths, n_steps+1) contenant les trajectoires simulées.\n",
    "        \"\"\"\n",
    "        rng = np.random.default_rng(seed)\n",
    "        S0 = self.S0 if S0 is None else float(S0)\n",
    "\n",
    "        dt = T / n_steps\n",
    "        vol = self.sigma * np.sqrt(dt)\n",
    "\n",
    "        paths = np.empty((n_paths, n_steps + 1))\n",
    "        paths[:, 0] = S0\n",
    "\n",
    "        if emm:\n",
    "            # Forwards annuels à partir de R(0,k) (taux continus)\n",
    "            # f_{0,1} = R(0,1), f_{k-1,k} = k*R(0,k) - (k-1)*R(0,k-1)\n",
    "            R = np.asarray(rate_curve, float)                     # shape (K,)\n",
    "            K = len(R)\n",
    "            forwards = np.empty(K, dtype=float)\n",
    "            forwards[0] = R[0]\n",
    "            for k in range(2, K + 1):\n",
    "                forwards[k - 1] = k * R[k - 1] - (k - 1) * R[k - 2]\n",
    "\n",
    "            # Pas par an (arrondi simple), répéter chaque forward\n",
    "            steps_per_year = int(round(n_steps / T))\n",
    "            n_years_needed = int(np.ceil(T))\n",
    "            f_yearly = np.concatenate([forwards, np.repeat(forwards[-1], max(0, n_years_needed - K))])[:n_years_needed]\n",
    "            r_t = np.repeat(f_yearly, steps_per_year)[:n_steps]   # longueur n_steps\n",
    "            drift_t = (r_t - self.q - 0.5 * self.sigma**2) * dt\n",
    "        else:\n",
    "            drift_t = np.full(n_steps, (self.mu - self.q - 0.5 * self.sigma**2) * dt)\n",
    "\n",
    "        for t in range(1, n_steps + 1):   # à vectoriser pour aller plus vite\n",
    "            z = rng.standard_normal(n_paths)\n",
    "            paths[:, t] = paths[:, t - 1] * np.exp(drift_t[t - 1] + vol * z)\n",
    "\n",
    "        return paths\n",
    "\n",
    "    # ---------- SÉRIALISATION ----------\n",
    "    def to_dict(self) -> dict:\n",
    "        \"\"\"\n",
    "        Retourne l'état courant de l’objet sous forme de dictionnaire.\n",
    "\n",
    "        Retour\n",
    "        ------\n",
    "        dict\n",
    "            {\"S0\": ..., \"mu\": ..., \"sigma\": ..., \"q\": ..., \"dt\": ..., \"meta\": {...}}\n",
    "        \"\"\"\n",
    "        return {\"S0\": self.S0, \"mu\": self.mu, \"sigma\": self.sigma, \"q\": self.q, \"dt\": self.dt, \"meta\": dict(self.meta)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db813370",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## 3. Validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c851302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramètres calibrés :\n",
      "  S0 = 95.87\n",
      "  mu = 0.06864064962644137\n",
      "  sigma = 0.2562856825729221\n",
      "  q = 0.0\n",
      "  dt = 0.019158857846701696\n",
      "  meta = {'method': 'historical_mle', 'n_obs': 1347, 'dt': 0.019158857846701696}\n"
     ]
    }
   ],
   "source": [
    "# Création + calibration\n",
    "model = BlackScholes()\n",
    "model.dt = model.infer_dt_from_dates(df[\"Date\"])\n",
    "mu, sigma = model.fit_from_prices(df[\"Stock Value\"].values[::-1]) \n",
    "\n",
    "# --- Récupérer les paramètres calibrés ---\n",
    "params = model.to_dict()\n",
    "S0   = float(params[\"S0\"])\n",
    "mu   = float(params[\"mu\"])\n",
    "sigma= float(params[\"sigma\"])\n",
    "q    = float(params[\"q\"])\n",
    "dt   = float(params[\"dt\"])\n",
    "\n",
    "# Paramètres calibrés\n",
    "params = model.to_dict()\n",
    "print(\"Paramètres calibrés :\")\n",
    "for k, v in params.items():\n",
    "    print(f\"  {k} = {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0677ed8",
   "metadata": {},
   "source": [
    "#### Comparaison des moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36fa5a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Moments empiriques au pas dt ----------\n",
    "def empirical_moments_dt(log_ret: np.ndarray) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calcule la moyenne et la variance empiriques de Δln S_t.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    log_ret : np.ndarray\n",
    "        Log-returns au pas dt.\n",
    "    \n",
    "    Retour\n",
    "    ------\n",
    "    (m_emp, v_emp) : tuple[float, float]\n",
    "        Moyenne et variance empiriques de Δln S_t.\n",
    "    \"\"\"\n",
    "    m_emp = float(np.mean(log_ret))\n",
    "    v_emp = float(np.var(log_ret))\n",
    "    return m_emp, v_emp\n",
    "\n",
    "# ---------- Moments théoriques au pas dt ----------\n",
    "def theoretical_moments_dt(mu: float, sigma: float, dt: float) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Moments théoriques de Δln S_t sous GBM : \n",
    "    E[Δln S] = (mu - 0.5*sigma^2)*dt, Var[Δln S] = sigma^2*dt.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    mu : float\n",
    "        Drift sous P (continu, annualisé).\n",
    "    sigma : float\n",
    "        Volatilité (continue, annualisée).\n",
    "    dt : float\n",
    "        Pas de temps en années.\n",
    "    \n",
    "    Retour\n",
    "    ------\n",
    "    (m_th, v_th) : tuple[float, float]\n",
    "        Moyenne et variance théoriques de Δln S_t.\n",
    "    \"\"\"\n",
    "    m_th = (mu - 0.5 * sigma**2) * dt\n",
    "    v_th = (sigma**2) * dt\n",
    "    return m_th, v_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad58ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical_moments_dt : {'mean': 0.0006858770348951168, 'var': 0.0012583988276062624}\n",
      "theoretical_moments_dt : {'mean': 0.0006858770348951168, 'var': 0.0012583988276062624}\n"
     ]
    }
   ],
   "source": [
    "prices = df[\"Stock Value\"].values[::-1]  \n",
    "log_ret = np.diff(np.log(prices))\n",
    "\n",
    "# moments empiriques\n",
    "m_emp, v_emp = empirical_moments_dt(log_ret)\n",
    "\n",
    "# moments théoriques sous GBM\n",
    "m_th, v_th = theoretical_moments_dt(model.mu, model.sigma, model.dt)\n",
    "\n",
    "print(\"empirical_moments_dt :\", {\"mean\": m_emp, \"var\": v_emp})\n",
    "print(\"theoretical_moments_dt :\", {\"mean\": m_th, \"var\": v_th})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeeeb4d",
   "metadata": {},
   "source": [
    "#### Check résidus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8349222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Résidus standardisés ----------\n",
    "def standardized_residuals(log_ret: np.ndarray, m_th: float, v_th: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Résidus standardisés : eps_t = (Δln S_t - m_th) / sqrt(v_th).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    log_ret : np.ndarray\n",
    "        Log-returns observés au pas dt.\n",
    "    m_th : float\n",
    "        Moyenne théorique de Δln S_t.\n",
    "    v_th : float\n",
    "        Variance théorique de Δln S_t.\n",
    "    \n",
    "    Retour\n",
    "    ------\n",
    "    np.ndarray\n",
    "        Résidus standardisés eps_t (attendu ~ N(0,1) i.i.d. sous GBM).\n",
    "    \"\"\"\n",
    "    return (log_ret - m_th) / np.sqrt(v_th)\n",
    "\n",
    "\n",
    "def residuals_stats(eps: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Statistiques de base des résidus standardisés.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eps : np.ndarray\n",
    "        Résidus standardisés.\n",
    "    \n",
    "    Retour\n",
    "    ------\n",
    "    dict\n",
    "        {'mean', 'var', 'skew', 'kurt'} (kurtose totale, 3 pour N(0,1)).\n",
    "    \"\"\"\n",
    "    mean = float(np.mean(eps))\n",
    "    var = float(np.var(eps))\n",
    "    std = np.sqrt(var)\n",
    "    skew = float(np.mean(((eps - mean) / std)**3))\n",
    "    kurt = float(np.mean(((eps - mean) / std)**4))  # kurtose totale\n",
    "    return {\"mean\": mean, \"var\": var, \"skew (normal = 0)\": skew, \"kurt (normal = 3)\": kurt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "061f48ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "residuals_stats : {'mean': 2.5056258313737757e-17, 'var': 1.0, 'skew (normal = 0)': -0.2252735817980989, 'kurt (normal = 3)': 6.587516730708788}\n"
     ]
    }
   ],
   "source": [
    "eps = standardized_residuals(log_ret, m_th, v_th)\n",
    "stats_eps = residuals_stats(eps)\n",
    "print(\"residuals_stats :\", stats_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aba74d",
   "metadata": {},
   "source": [
    "#### Check simul paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66e6bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-step moments comparison\n",
      "- Empirical (history):   mean = 6.858770e-04, var = 1.258399e-03\n",
      "- Theoretical (GBM):     mean = 6.858770e-04, var = 1.258399e-03\n",
      "- Simulated (1 path):    mean = 2.901899e-04, var = 1.184017e-03\n",
      "\n",
      "Relative errors (vs empirical):\n",
      "  mean: -57.69%   var: -5.91%\n",
      "Relative errors (vs theoretical):\n",
      "  mean: -57.69%    var: -5.91%\n"
     ]
    }
   ],
   "source": [
    "n_steps = len(log_ret)                 \n",
    "T = n_steps * model.dt                \n",
    "\n",
    "# Simuler une trajectoire\n",
    "paths_1 = model.simulate_paths(T=T, n_steps=n_steps, n_paths=100, seed=42)\n",
    "sim_prices = paths_1[0]\n",
    "sim_prices = sim_prices[::-1]  # Penser à inverser\n",
    "sim_log_ret = np.diff(np.log(sim_prices))\n",
    "\n",
    "# Moments simulés \n",
    "m_sim = float(np.mean(sim_log_ret))\n",
    "v_sim = float(np.var(sim_log_ret, ddof=1))\n",
    "\n",
    "# Affichage comparatif\n",
    "print(\"Per-step moments comparison\")\n",
    "print(f\"- Empirical (history):   mean = {m_emp:.6e}, var = {v_emp:.6e}\")\n",
    "print(f\"- Theoretical (GBM):     mean = {m_th:.6e}, var = {v_th:.6e}\")\n",
    "print(f\"- Simulated (1 path):    mean = {m_sim:.6e}, var = {v_sim:.6e}\")\n",
    "\n",
    "# Écarts relatifs (par rapport à l'empirique et au théorique)\n",
    "def rel_err(a, b): \n",
    "    return (a - b) / (1e-12 if b == 0 else b)\n",
    "\n",
    "print(\"\\nRelative errors (vs empirical):\")\n",
    "print(f\"  mean: {rel_err(m_sim, m_emp):+.2%}   var: {rel_err(v_sim, v_emp):+.2%}\")\n",
    "\n",
    "print(\"Relative errors (vs theoretical):\")\n",
    "print(f\"  mean: {rel_err(m_sim, m_th):+.2%}    var: {rel_err(v_sim, v_th):+.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "11eaa7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-step moments comparison (100 paths)\n",
      "- Empirical (history):   mean = 6.858770e-04, var = 1.258399e-03\n",
      "- Theoretical (GBM):     mean = 6.858770e-04, var = 1.258399e-03\n",
      "- Simulated (10000 paths): mean = 6.874280e-04, var = 1.257990e-03\n"
     ]
    }
   ],
   "source": [
    "n_steps = len(log_ret)                 \n",
    "T = n_steps * model.dt                \n",
    "\n",
    "# Simuler 1000 trajectoires\n",
    "paths = model.simulate_paths(T=T, n_steps=n_steps, n_paths=10000, seed=42)\n",
    "\n",
    "# Calcul des log-returns sur toutes les trajectoires\n",
    "# np.diff marche sur l’axe 1, puis on aplati pour tout agréger\n",
    "sim_log_ret = np.diff(np.log(paths), axis=1).ravel()\n",
    "\n",
    "#  Moments simulés (par pas)\n",
    "m_sim = float(np.mean(sim_log_ret))\n",
    "v_sim = float(np.var(sim_log_ret, ddof=1))\n",
    "\n",
    "#  Affichage comparatif\n",
    "print(\"Per-step moments comparison (100 paths)\")\n",
    "print(f\"- Empirical (history):   mean = {m_emp:.6e}, var = {v_emp:.6e}\")\n",
    "print(f\"- Theoretical (GBM):     mean = {m_th:.6e}, var = {v_th:.6e}\")\n",
    "print(f\"- Simulated (10000 paths): mean = {m_sim:.6e}, var = {v_sim:.6e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
